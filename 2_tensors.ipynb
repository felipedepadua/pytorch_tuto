{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9698, 0.9004],\n",
      "        [0.5741, 0.9226]])\n",
      "tensor([[0.3037, 0.1658],\n",
      "        [0.2522, 0.8974]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2735, 1.0662],\n",
      "        [0.8262, 1.8200]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.add(x, y)  # Same as 'z = x + y'\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2735, 1.0662],\n",
      "        [0.8262, 1.8200]])\n"
     ]
    }
   ],
   "source": [
    "# or an in-place operation (PS: in-plave operations have a \"_\" at the end)\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5621, -0.3789],\n",
      "        [ 0.2914, -0.0699]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "z = a - x  # or torch.sub(a,x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other functions:\n",
    "# torch.mul(a,x) - OR a.mul_(x) for in-place [will modify 'a'] - OR 'a * x'\n",
    "# torch.div \n",
    "# etc.\n",
    "# EXTRA: 'a @ x' (is equilavent to do the matrix multiplication between 'a' and 'x')\n",
    "#         Or you can use 'a.matmul(x)' (or torch.matmul(a,x, out=<any_var>))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1643, 0.7283, 0.2154],\n",
      "        [0.6831, 0.8369, 0.5627],\n",
      "        [0.9321, 0.4373, 0.5476],\n",
      "        [0.7194, 0.4270, 0.6299],\n",
      "        [0.0186, 0.2397, 0.7174]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.rand(5, 3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1643, 0.6831, 0.9321, 0.7194, 0.0186])\n",
      "tensor([0.6831, 0.8369, 0.5627])\n"
     ]
    }
   ],
   "source": [
    "# Slicing\n",
    "print(b[:,0]) # all the rows but only column 0\n",
    "print(b[1,:]) # only row 1 and all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "0.16427046060562134\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# get a value (a tensor) and then convert to a primitive type '.item()'\n",
    "print(b[0,0].dtype)\n",
    "bb = b[0,0].item() # PS: this function only works if you have one element\n",
    "print(bb)\n",
    "print(type(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping a tensor\n",
    "c = b.view(3,5) # one dimension\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# From numpy to a tensor (and vice-versa)\n",
    "import numpy as np\n",
    "\n",
    "d = torch.ones(5)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "d_np = d.numpy() #convert to numpy\n",
    "print(d_np)\n",
    "print(type(d_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTANT: both objects ('d' and 'd_np') will share the same memory location (if on GPU)\n",
    "#            Therefore, if you change one, you'll also change the other.\n",
    "\n",
    "d.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Now you should see the same values\n",
    "print(d)\n",
    "print(d_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4076, 0.5215],\n",
      "        [0.8654, 0.8527]])\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# From a numpy to tensor\n",
    "\n",
    "e_np = np.ones(5)\n",
    "print(a)\n",
    "\n",
    "e = torch.from_numpy(e_np)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 4., 4., 4., 4.], dtype=torch.float64)\n",
      "[4. 4. 4. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "# PS: This is higher than 2 because I ran this command many times (it keeps adding 1)\n",
    "e += 1\n",
    "print(e)\n",
    "print(e_np) # should always be the same as 'e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have GPU, you can do this\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x_gpu = torch.ones(5, device=device)\n",
    "    # OR (same as above):\n",
    "    x2_gpu = torch.ones(5).to(device)\n",
    "    # Now if you do any operation (e.g. the below), it will be done in the GPU\n",
    "    x_gpu +=1\n",
    "    # PS: If you try to transform it back into a numpy array (x_gpu.numpy()), that'll error!\n",
    "    # That is because numpy can only handle CPU tensors\n",
    "    # To do that conversion to numpy, you have to conver to a CPU tensor first:\n",
    "    x_gpu = x2_gpu.to(\"cpu\") #Now on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    a = a.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE ON IN-PLACE OPERATION (from official documentation):\n",
    "# In-place operations save some memory, but can be problematic when computing derivatives because of\n",
    "# an immediate loss of history. Hence, their use is discouraged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tuto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13c53d24e4d88d3a912c0a93e107616508f30ae1ad473cd537d575b47c4ae4a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

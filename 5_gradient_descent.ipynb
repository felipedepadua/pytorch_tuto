{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = np.array([1,2,3,4], dtype=np.float32)\n",
    "Y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# Loss = MSE = 1/N * (w*x - y)**2\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()\n",
    "\n",
    "# Gradient\n",
    "def gradient(x, y, y_pred):\n",
    "    return np.dot(2*x, y_pred-y).mean() # dJ/dw = 1/N * 2x (w*x - y) [Derivative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "Epoch: 1: w = 1.200, loss = 30.00000000\n",
      "Epoch: 2: w = 1.680, loss = 4.79999924\n",
      "Epoch: 3: w = 1.872, loss = 0.76800019\n",
      "Epoch: 4: w = 1.949, loss = 0.12288000\n",
      "Epoch: 5: w = 1.980, loss = 0.01966083\n",
      "Epoch: 6: w = 1.992, loss = 0.00314570\n",
      "Epoch: 7: w = 1.997, loss = 0.00050332\n",
      "Epoch: 8: w = 1.999, loss = 0.00008053\n",
      "Epoch: 9: w = 1.999, loss = 0.00001288\n",
      "Epoch: 10: w = 2.000, loss = 0.00000206\n",
      "Epoch: 11: w = 2.000, loss = 0.00000033\n",
      "Epoch: 12: w = 2.000, loss = 0.00000005\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iterations = 12\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients\n",
    "    dw = gradient(X, Y, y_pred)\n",
    "\n",
    "    # Update weights (Go in the negative direction)\n",
    "    w -= learning_rate * dw\n",
    "\n",
    "    if epoch % 1 == 0: # PS: change the value to '2' to print only every other epoch\n",
    "        print(f'Epoch: {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = w * x (So 'w' should be 2 for us to get the right formula, which is 'f = 2 * x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW LET'S START USING PYTORCH AND ELIMINATE THE MANUAL GRADIENT FUNCTION\n",
    "# Prediction: Manual\n",
    "# Gradients Computation: Autograd\n",
    "# Loss Computation: Manual\n",
    "# Parameter Updates: Manual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# f = w * x\n",
    "\n",
    "# f = 2 * x\n",
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Loss function are still the same (no need for the 'gradient' function anymore though)\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# Loss = MSE = 1/N * (w*x - y)**2\n",
    "def loss(y, y_pred):\n",
    "    return ((y_pred - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "Epoch: 1: w = 0.300, loss = 30.00000000\n",
      "Epoch: 4: w = 0.956, loss = 11.31448650\n",
      "Epoch: 7: w = 1.359, loss = 4.26725292\n",
      "Epoch: 10: w = 1.606, loss = 1.60939169\n",
      "Epoch: 13: w = 1.758, loss = 0.60698116\n",
      "Epoch: 16: w = 1.851, loss = 0.22892261\n",
      "Epoch: 19: w = 1.909, loss = 0.08633806\n",
      "Epoch: 22: w = 1.944, loss = 0.03256231\n",
      "Epoch: 25: w = 1.966, loss = 0.01228084\n",
      "Epoch: 28: w = 1.979, loss = 0.00463169\n",
      "Epoch: 31: w = 1.987, loss = 0.00174685\n",
      "Epoch: 34: w = 1.992, loss = 0.00065882\n",
      "Epoch: 37: w = 1.995, loss = 0.00024848\n",
      "Epoch: 40: w = 1.997, loss = 0.00009371\n",
      "Prediction after training: f(5) = 9.985\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# Training\n",
    "learning_rate = 0.01\n",
    "n_iterations = 40\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    # prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # Loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # Gradients = backward pass\n",
    "    l.backward() # dl/dw\n",
    "\n",
    "    # Update weights\n",
    "    with torch.no_grad(): # Use this as the weights should not be part of the computation graph\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    # We have to empty the gradients\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 3 == 0: # Print every 3 steps\n",
    "        print(f'Epoch: {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
    "\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS: It uses a different backward propagation.\n",
    "# That's why, in this case, it took longer to get closer to the right answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tuto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13c53d24e4d88d3a912c0a93e107616508f30ae1ad473cd537d575b47c4ae4a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
